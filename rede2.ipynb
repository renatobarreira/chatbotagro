{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff443d4-211a-4d8e-a2e6-8af004f2b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10f8261d-2772-41b5-b436-2295e9adb4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Nenhuma GPU detectada. O treinamento será feito na CPU (mais lento).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#não estou conseguindo fazer funcionar, mas nem é necessário já q são dados tabulares e são poucos.\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        #não sei pra q serve mas tá escrito q isso faz com que o TensorFlow pegue memória aos poucos, e não toda de uma vez.\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        print(f\"✅ GPU Encontrada: {gpus}\")\n",
    "        print(\"O treinamento será acelerado pela placa de vídeo!\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"❌ Nenhuma GPU detectada. O treinamento será feito na CPU (mais lento).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7127c9b4-29fc-41c1-b272-747c369dd929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando o banco de dados e tirando os espaços pq é foda né\n",
    "df = pd.read_csv('paddydataset.csv')\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "950724b5-886e-4580-8efb-5ae77d86b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar Features (X) selecionadas e alvo (y)\n",
    "#por enquanto o alvo é a última coluna: 'Paddy yield(in Kg), talvez mudar?'\n",
    "features = [\n",
    "    'Hectares', 'Variety', 'Soil Types', \n",
    "    'Seedrate(in Kg)', 'Nursery area (Cents)', 'LP_Mainfield(in Tonnes)',\n",
    "    'DAP_20days', 'Urea_40Days', 'Potassh_50Days', 'Micronutrients_70Days',\n",
    "    'Weed28D_thiobencarb', 'Pest_60Day(in ml)'\n",
    "]\n",
    "target = 'Paddy yield(in Kg)'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b36bec23-b79e-4898-9c2c-135250621137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pré-processamento Identificar colunas numéricas e categóricas, tava escrito pra fazer só fiz\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "390f61a2-d407-407f-b834-ccb2f8173f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processamento\n",
    "#identificar tipos automaticamente\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "num_cols = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8057884e-9a52-4e09-877a-3cb4ba39501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clásico sem mt firula dividindo em Treino e Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "448b42fa-4ac7-4467-9fba-e5734b096916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converter para denso se necessário não sei exatamente oq faz mas to com medo de tirar\n",
    "if hasattr(X_train, \"toarray\"): X_train = X_train.toarray()\n",
    "if hasattr(X_test, \"toarray\"): X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba9492c-6bea-409d-b3b9-6f1eb8cef00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 590074560.0000 - mae: 22463.2207  \n",
      "Epoch 2/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 584722368.0000 - mae: 22346.4199\n",
      "Epoch 3/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 549610432.0000 - mae: 21556.1895\n",
      "Epoch 4/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 439636928.0000 - mae: 18995.9668\n",
      "Epoch 5/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 257638960.0000 - mae: 14629.4111\n",
      "Epoch 6/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 105740096.0000 - mae: 9140.8096\n",
      "Epoch 7/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 56192360.0000 - mae: 6340.8608\n",
      "Epoch 8/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 45239696.0000 - mae: 5351.8662\n",
      "Epoch 9/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 37321948.0000 - mae: 4726.4556\n",
      "Epoch 10/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32074306.0000 - mae: 4367.3027\n",
      "Epoch 11/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 28731102.0000 - mae: 4144.7188\n",
      "Epoch 12/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 25805316.0000 - mae: 3907.9548\n",
      "Epoch 13/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 22958674.0000 - mae: 3688.4097\n",
      "Epoch 14/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 20028748.0000 - mae: 3430.9995\n",
      "Epoch 15/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 17117654.0000 - mae: 3170.4705\n",
      "Epoch 16/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 14219262.0000 - mae: 2868.0547\n",
      "Epoch 17/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 11547525.0000 - mae: 2573.1279\n",
      "Epoch 18/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 9225854.0000 - mae: 2306.6812\n",
      "Epoch 19/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 7276830.5000 - mae: 2047.9922\n",
      "Epoch 20/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 5692392.5000 - mae: 1827.7983\n",
      "Epoch 21/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 4426725.5000 - mae: 1630.2097\n",
      "Epoch 22/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 3493307.7500 - mae: 1444.1885\n",
      "Epoch 23/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 2793749.5000 - mae: 1290.9268\n",
      "Epoch 24/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 2297337.2500 - mae: 1176.5466\n",
      "Epoch 25/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 1918813.8750 - mae: 1062.5499\n",
      "Epoch 26/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 1639122.8750 - mae: 985.4473 \n",
      "Epoch 27/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1443991.0000 - mae: 922.5853  \n",
      "Epoch 28/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1300806.7500 - mae: 876.1985\n",
      "Epoch 29/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 1194820.5000 - mae: 828.8267\n",
      "Epoch 30/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 1115857.1250 - mae: 803.8117\n",
      "Epoch 31/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 1053285.1250 - mae: 777.1920\n",
      "Epoch 32/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 1011543.8750 - mae: 754.9560\n",
      "Epoch 33/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 970009.3750 - mae: 737.1284   \n",
      "Epoch 34/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 943484.3750 - mae: 715.4102\n",
      "Epoch 35/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 924576.4375 - mae: 710.3687\n",
      "Epoch 36/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 906801.6875 - mae: 700.5522\n",
      "Epoch 37/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 896156.2500 - mae: 690.6381\n",
      "Epoch 38/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 888225.7500 - mae: 687.2467\n",
      "Epoch 39/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 880871.1875 - mae: 674.2748\n",
      "Epoch 40/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 883430.3750 - mae: 682.1690\n",
      "Epoch 41/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 869650.8125 - mae: 673.0134\n",
      "Epoch 42/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 867035.9375 - mae: 669.9723  \n",
      "Epoch 43/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 862232.1250 - mae: 663.9141\n",
      "Epoch 44/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 861622.2500 - mae: 666.9976\n",
      "Epoch 45/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 855632.6250 - mae: 658.0103\n",
      "Epoch 46/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 854109.5625 - mae: 657.0103\n",
      "Epoch 47/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 860253.8750 - mae: 656.6193\n",
      "Epoch 48/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 851701.3750 - mae: 653.9800  \n",
      "Epoch 49/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 850813.7500 - mae: 649.4068\n",
      "Epoch 50/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 846598.3750 - mae: 650.0031\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 853525.1250 - mae: 678.7626 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo Erro Médio (MAE): 678.76 Kg\n"
     ]
    }
   ],
   "source": [
    "#multilayer perceptron bem basiquinha sem mt presepada\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "#avaliação\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Novo Erro Médio (MAE): {mae:.2f} Kg\")\n",
    "\n",
    "#salvar\n",
    "model.save('modelo_paddy_compacto.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
